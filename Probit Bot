import torch
import torch.nn as nn
import requests
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Check if GPU is available, otherwise use CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Define the LSTM class
class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# Function to fetch Bitcoin price data and other features from XT.com API
def fetch_bitcoin_data():
    api_key = 'f8c4e98f-b533-4ca7-8e36-51e3b1aa8042'
    url = f'https://api.xt.com/data/market/kline?market_id=1&interval=1day&begin=1638883200&end=1640883200&limit=30&api_key={api_key}'
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        # Extracting relevant features (open, high, low, close prices, and volume) from the API response
        bitcoin_data = pd.DataFrame(data['kline'], columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        bitcoin_data['timestamp'] = pd.to_datetime(bitcoin_data['timestamp'], unit='s')
        bitcoin_data.set_index('timestamp', inplace=True)
        # For demonstration purposes, let's calculate the difference between high and low prices as an additional feature
        bitcoin_data['price_range'] = bitcoin_data['high'] - bitcoin_data['low']
        return bitcoin_data
    else:
        print("Failed to fetch data:", response.status_code)
        return None

# Function to preprocess data
def preprocess_data(bitcoin_data):
    # Handle missing values, if any (not implemented in this example)
    # Normalize the data
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(bitcoin_data)
    return scaled_data, scaler

# Function to split data into train and test sets
def split_data(data):
    X = data[:, :-1]  # Features (all columns except the last one)
    y = data[:, -1]   # Target variable (last column)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test

# Function to train the model
def train_model(model, X_train, y_train, epochs=100, lr=0.001):
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    for epoch in range(epochs):
        inputs = torch.tensor(X_train, dtype=torch.float32).to(device)
        targets = torch.tensor(y_train, dtype=torch.float32).to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs.squeeze(), targets)
        loss.backward()
        optimizer.step()
        if (epoch+1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# Function to evaluate the model
def evaluate_model(model, X_test, y_test):
    inputs = torch.tensor(X_test, dtype=torch.float32).to(device)
    targets = torch.tensor(y_test, dtype=torch.float32).to(device)
    with torch.no_grad():
        outputs = model(inputs)
        mse = mean_squared_error(targets.cpu().numpy(), outputs.squeeze().cpu().numpy())
    print(f'Mean Squared Error (MSE) on Test Set: {mse:.4f}')

# Function to implement trading strategy
def trading_strategy(model, scaled_data, scaler):
    inputs = torch.tensor(scaled_data, dtype=torch.float32).to(device)
    with torch.no_grad():
        outputs = model(inputs)
    # Implement your trading strategy based on model predictions
    # For demonstration, let's plot the predictions
    unscaled_outputs = scaler.inverse_transform(outputs.cpu().numpy())
    plt.plot(unscaled_outputs, label='Predictions')
    plt.xlabel('Time')
    plt.ylabel('Bitcoin Price')
    plt.title('Bitcoin Price Predictions')
    plt.legend()
    plt.show()

# Function to backtest the trading strategy
def backtest_trading_strategy(model, scaled_data, scaler):
    inputs = torch.tensor(scaled_data, dtype=torch.float32).to(device)
    with torch.no_grad():
        outputs = model(inputs)
    # For demonstration, let's calculate the cumulative returns of the trading strategy
    unscaled_outputs = scaler.inverse_transform(outputs.cpu().numpy())
    returns = np.diff(unscaled_outputs.squeeze(), prepend=0) / unscaled_outputs[:-1] * 100
    cumulative_returns = np.cumsum(returns)
    plt.plot(cumulative_returns, label='Cumulative Returns')
    plt.xlabel('Time')
    plt.ylabel('Cumulative Returns (%)')
    plt.title('Backtesting Trading Strategy')
    plt.legend()
    plt.show()

# Function to manage risk
def risk_management(model, scaled_data, scaler):
    inputs = torch.tensor(scaled_data, dtype=torch.float32).to(device)
    with torch.no_grad():
        outputs = model(inputs)
    # For demonstration, let's calculate the volatility of the predictions
    unscaled_outputs = scaler.inverse_transform(outputs.cpu().numpy())
    volatility = np.std(np.diff(unscaled_outputs.squeeze()))
    print(f"Volatility of the predictions: {volatility:.4f}")

# Function to deploy the trading bot
def deploy_trading_bot(model, scaler):
    # Placeholder for deployment logic
    # For demonstration, let's save the trained model and scaler for future use
    torch.save(model.state_dict(), 'trained_model.pth')
    torch.save(scaler, 'scaler.pkl')
    print("Trading bot deployed successfully!")

# Main function
def main():
    # Fetch Bitcoin price data and other features
    bitcoin_data = fetch_bitcoin_data()

    if bitcoin_data is not None:
        # Preprocess data
        scaled_data, scaler = preprocess_data(bitcoin_data)

        # Split data into train and test sets
        X_train, X_test, y_train, y_test = split_data(scaled_data)

        # Define hyperparameters
        input_size = scaled_data.shape[1] - 1  # Number of input features
        hidden_size = 64  # Number of hidden units in the LSTM layer
        num_layers = 2  # Number of LSTM layers
        output_size = 1  # Number of output units

        # Instantiate the model
        model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)

        # Train the model
        train_model(model, X_train, y_train)

        # Evaluate the model
        evaluate_model(model, X_test, y_test)

        # Implement trading strategy
        trading_strategy(model, scaled_data, scaler)

        # Backtest the trading strategy
        backtest_trading_strategy(model, scaled_data, scaler)

        # Manage risk
        risk_management(model, scaled_data, scaler)

        # Deploy the trading bot
        deploy_trading_bot(model, scaler)

if __name__ == '__main__':
    main()
